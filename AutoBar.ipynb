{"cells":[{"cell_type":"markdown","metadata":{},"source":["![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n","# Prompt Notebook with Chat - Prompt Lab Notebook v1.1.0\n","This notebook contains steps and code to demonstrate inferencing of prompts\n","generated in Prompt Lab in watsonx.ai with a chat format. It introduces Python API commands\n","for authentication using API key and prompt inferencing using WML API.\n","\n","**Note:** Notebook code generated using Prompt Lab will execute successfully.\n","If code is modified or reordered, there is no guarantee it will successfully execute.\n","For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Prompt Lab as a notebook.</a>\n","\n","Some familiarity with Python is helpful. This notebook uses Python 3.10.\n","\n","## Notebook goals\n","The learning goals of this notebook are:\n","\n","* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n","* Defining parameters of the Model object\n","* Using the Model object to generate response using the defined model id, parameters and the prompt input\n","\n","# Setup"]},{"cell_type":"markdown","metadata":{},"source":["## watsonx API connection\n","This cell defines the credentials required to work with watsonx API for Foundation\n","Model inferencing.\n","\n","**Action:** Provide the IBM Cloud personal API key. For details, see\n","<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["import os\n","import getpass\n","\n","def get_credentials():\n","\treturn {\n","\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n","\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n","\t}\n"]},{"cell_type":"markdown","metadata":{},"source":["# Inferencing\n","This cell demonstrated how we can use the model object as well as the created access token\n","to pair it with parameters and input string to obtain\n","the response from the the selected foundation model.\n","\n","## Defining the model id\n","We need to specify model id that will be used for inferencing:\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["model_id = \"ibm/granite-13b-chat-v2\"\n"]},{"cell_type":"markdown","metadata":{},"source":["## Defining the model parameters\n","We need to provide a set of model parameters that will influence the\n","result:"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["parameters = {\n","    \"decoding_method\": \"greedy\",\n","    \"max_new_tokens\": 900,\n","    \"repetition_penalty\": 1.05\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## Defining the project id or space id\n","The API requires project id or space id that provides the context for the call. We will obtain\n","the id from the project or space in which this notebook runs:"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["project_id = os.getenv(\"PROJECT_ID\") #\n","space_id = os.getenv(\"SPACE_ID\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Defining the Model object\n","We need to define the Model object using the properties we defined so far:\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Please enter your api key (hit enter): ········\n"]}],"source":["from ibm_watsonx_ai.foundation_models import Model\n","\n","model = Model(\n","\tmodel_id = model_id,\n","\tparams = parameters,\n","\tcredentials = get_credentials(),\n","\tproject_id = project_id,\n","\tspace_id = space_id\n","\t)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Defining the inferencing input for chat\n","Foundation models supporting chat accept a system prompt that instructs the model on how to conduct the dialog. They also accept previous questions and answers to give additional context when inferencing. Each model has it's own string format for constructing the input.\n","\n","Let us provide the input we got from the Prompt Lab and format it for the selected model:\n"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["prompt_input = \"\"\"<|system|>\n","You are Granite, an AI language model developed by IBM, integrated into a suite of four applications: ConnectX (for meetings), DocX (for document management), CalX (for calendar events), and MailX (for emails). Your primary role is to assist users by generating structured JSON responses only that automate tasks across these applications, based on the user's prompt.\n","When processing a user prompt, carefully analyze which applications are relevant and respond strictly using the following JSON format:\n","ConnectX: Return 1 if the prompt requires generating a meeting link, and 0 if it does not.\n","DocX: Return 1 if the prompt involves creating or editing a document, and 0 if it does not.\n","CalX: ONLY if the prompt involves a date-specific event, return a key-value (date-description) pair where the date is the key (formatted as DD-MM-YY), and a concise description (no more than 10 words) is the value. Otherwise return calX: 0. Always use the DD-MM-YY format for dates. Add multiple entries for mulitple dates or days.\n","MailX: If the prompt includes the need to generate an email, return the subject (max 12 words) and the body (max 300 words) as key-value pairs. If no email is needed, return mailX: 0. If the user explicitly states that no email is required, always ensure to set mailX: 0.\n","Key Rules:\n","Do not provide any additional commentary, explanations, or text outside of the JSON structure under any circumstances. Always adhere strictly to the format and provide a fully structured and accurate JSON response based on the user prompt.\n","Never respond with any text other than the required JSON structure.\n","Never include comments or explanations alongside the JSON.\n","Always return the correct JSON structure based on the user’s input, ensuring compliance with the format.\n","The response must always be concise, precise, and limited to the exact JSON output.\n","Avoid calX events is not mentioned specifically.\n","Example JSON response:\n","{\n","  \"connectX\": 0,\n","  \"docX\": 0,\n","  \"calX\": {\n","    \"00-00-00\": \"Sign NDA\",},\n","  \"mailX\": {\n","    \"sub\": \"Reminder: NDA Signing Deadline – 00th February\",\n","    \"body\": \"I hope this message finds you well. I’m writing to remind you that the deadline for signing the Non-Disclosure Agreement (NDA) is approaching on 00-00\"\n","  }\n","}\n","\n","\"\"\"\n"]},{"cell_type":"markdown","metadata":{},"source":["## Execution\n","Let us now use the defined Model object, pair it with the input, and generate the response to your question:\n"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: Create four event for four consecutive days from 11th November 2024, with these titles, \"Day 1 Fest\", \"Day 2 Drama\", \"Day 3 Movie\", \"Day 4 Prizes\"\n","Here is the JSON representation of the requested events:\n","```json\n","{\n","  \"calX\": [\n","    {\n","      \"date\": \"11-11-2024\",\n","      \"description\": \"Day 1 Fest\"\n","    },\n","    {\n","      \"date\": \"12-11-2024\",\n","      \"description\": \"Day 2 Drama\"\n","    },\n","    {\n","      \"date\": \"13-11-2024\",\n","      \"description\": \"Day 3 Movie\"\n","    },\n","    {\n","      \"date\": \"14-11-2024\",\n","      \"description\": \"Day 4 Prizes\"\n","    }\n","  ]\n","}\n","```\n","In this JSON object, the `calX` array contains four objects, each representing an event with a date and a description. The dates are formatted as DD-MM-YY.\n"]}],"source":["question = input(\"Question: \")\n","formattedQuestion = f\"\"\"<|user|>\n","{question}\n","<|assistant|>\n","\"\"\"\n","prompt = f\"\"\"{prompt_input}{formattedQuestion}\"\"\"\n","generated_response = model.generate_text(prompt=prompt, guardrails=False)\n","print(f\"{generated_response}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Next steps\n","You successfully completed this notebook! You learned how to use\n","watsonx.ai inferencing SDK to generate response from the foundation model\n","based on the provided input, model id and model parameters. Check out the\n","official watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n","\n","<a id=\"copyrights\"></a>\n","### Copyrights\n","\n","Licensed Materials - Copyright © 2023 IBM. This notebook and its source code are released under the terms of the ILAN License.\n","Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n","\n","**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n","\n","By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":1}
